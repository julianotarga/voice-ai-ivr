# üéØ Guia de Implementa√ß√£o: Melhorias Conversacionais Voice AI IVR

## Contexto do Sistema

**Projeto**: Voice AI IVR (FreeSWITCH + OpenAI Realtime API)  
**Stack**: Python, WebSocket, ESL, OpenAI Realtime (gpt-4o-realtime)  
**Objetivo**: Tornar conversas telef√¥nicas com IA mais naturais e humanizadas

---

## üìã Roadmap de Implementa√ß√£o

### **P0 - Quick Wins (Implementar HOJE)**

#### 1Ô∏è‚É£ Fillers Naturais + Thinking Out Loud
**Problema**: Sil√™ncio durante function calls/processamento causa estranheza  
**Solu√ß√£o**: Enviar mensagem verbal antes de opera√ß√µes demoradas

**Localiza√ß√£o**: `voice-ai-service/realtime/providers/openai_realtime.py`

```python
# Adicionar no in√≠cio do arquivo
FILLERS = [
    "Hmm, deixa eu verificar isso pra voc√™...",
    "Um momento s√≥, vou buscar essa informa√ß√£o...",
    "Certo, s√≥ um segundo enquanto eu consulto...",
    "Entendi, deixa eu ver aqui...",
    "Perfeito, vou verificar isso agora..."
]

PROCESSING_NARRATION = {
    "request_handoff": [
        "Vou verificar a disponibilidade do atendente...",
        "Deixa eu ver quem pode te atender...",
    ],
    "check_availability": [
        "Consultando a disponibilidade...",
        "Verificando os hor√°rios dispon√≠veis...",
    ],
    "create_ticket": [
        "Vou criar um protocolo pra voc√™...",
        "Registrando sua solicita√ß√£o...",
    ]
}
```

**Implementa√ß√£o**:
```python
class OpenAIRealtimeProvider:
    
    async def _handle_function_call_start(self, function_name: str, arguments: dict):
        """Chamado ANTES de executar function call."""
        
        # Selecionar narra√ß√£o espec√≠fica ou filler gen√©rico
        if function_name in PROCESSING_NARRATION:
            message = random.choice(PROCESSING_NARRATION[function_name])
        else:
            message = random.choice(FILLERS)
        
        # Enviar mensagem de √°udio via OpenAI
        await self._send_conversation_item({
            "type": "message",
            "role": "assistant",
            "content": [{"type": "text", "text": message}]
        })
        
        # Pequeno delay para garantir que come√ßou a falar
        await asyncio.sleep(0.3)
```

**Integra√ß√£o**:
```python
# No m√©todo que processa function calls
async def _on_response_function_call_arguments_done(self, event: dict):
    call_id = event.get("call_id")
    name = event.get("name")
    arguments = json.loads(event.get("arguments", "{}"))
    
    # NOVO: Narrar antes de executar
    await self._handle_function_call_start(name, arguments)
    
    # Executar function call original
    result = await self._execute_function_call(name, arguments)
    
    # Enviar resultado de volta
    await self._send_function_result(call_id, result)
```

**Impacto**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  
- Elimina percep√ß√£o de "travamento"
- Lat√™ncia percebida reduzida em ~70%
- Usu√°rio sabe que est√° sendo atendido

---

#### 2Ô∏è‚É£ Confirma√ß√µes Variadas
**Problema**: IA soa rob√≥tica repetindo sempre "Ok", "Entendido"  
**Solu√ß√£o**: Prompt engineering com instru√ß√µes expl√≠citas

**Localiza√ß√£o**: `voice-ai-service/realtime/config/prompts.py` (criar se n√£o existir)

```python
# Criar arquivo de configura√ß√£o de prompts
CONVERSATIONAL_RULES = """
NATURALIDADE CONVERSACIONAL - REGRAS OBRIGAT√ìRIAS:

1. CONFIRMA√á√ïES VARIADAS:
   ‚úÖ Use: "Certo", "Entendido", "Perfeito", "Pode deixar", "Combinado", "T√° bom", "Anotado"
   ‚ùå Evite repetir: "Ok", "Entendo" mais de uma vez na mesma conversa

2. FILLERS NATURAIS:
   - Use "Hmm..." quando estiver processando
   - Use "Deixa eu ver..." antes de consultas
   - Use "Ah, entendi..." quando compreender contexto

3. COER√äNCIA:
   - Varie suas respostas mesmo para situa√ß√µes similares
   - N√£o use a mesma frase duas vezes seguidas
   - Seja natural, n√£o pare√ßa um script

Exemplos:
‚ùå RUIM:
User: "Preciso falar com vendas"
AI: "Ok. Vou transferir."
User: "Obrigado"  
AI: "Ok. At√© logo."

‚úÖ BOM:
User: "Preciso falar com vendas"
AI: "Perfeito! Vou te passar para o setor de vendas."
User: "Obrigado"
AI: "Por nada! Tenha um √≥timo atendimento."
"""

# System prompt principal
def get_system_prompt(company_name: str, secretary_name: str) -> str:
    return f"""
Voc√™ √© {secretary_name}, secret√°ria virtual da empresa {company_name}.
Voc√™ √© profissional, amig√°vel e eficiente.

{CONVERSATIONAL_RULES}

Suas principais fun√ß√µes:
- Atender chamadas e entender a necessidade do cliente
- Transferir para o setor/pessoa adequada quando necess√°rio
- Criar protocolos de atendimento quando n√£o houver atendentes dispon√≠veis
- Fornecer informa√ß√µes b√°sicas sobre a empresa

Seja sempre cort√™s, clara e objetiva.
"""
```

**Integra√ß√£o**:
```python
# No OpenAIRealtimeProvider.__init__
from realtime.config.prompts import get_system_prompt

class OpenAIRealtimeProvider:
    async def initialize_session(self):
        # Gerar prompt personalizado
        system_prompt = get_system_prompt(
            company_name=self.config.company_name,
            secretary_name=self.config.secretary_name
        )
        
        # Enviar configura√ß√£o de sess√£o
        session_update = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": system_prompt,  # Prompt melhorado
                "voice": self.config.voice,
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                # ... resto da config
            }
        }
        await self.ws.send(json.dumps(session_update))
```

**Impacto**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  
- Zero c√≥digo, apenas prompt
- Melhoria imediata na naturalidade
- F√°cil de iterar e refinar

---

### **P1 - Alto Impacto (Pr√≥xima Sprint)**

#### 3Ô∏è‚É£ Suaviza√ß√£o de Transi√ß√µes
**Problema**: Transfer√™ncias abruptas ("Vou transferir. [MOH]")  
**Solu√ß√£o**: Anunciar transfer√™ncia de forma natural e completa

**Localiza√ß√£o**: `voice-ai-service/realtime/transfer/transfer_manager.py`

```python
class TransferManager:
    
    TRANSFER_ANNOUNCEMENTS = [
        "Perfeito! Vou te conectar com {agent_name} do {department}. "
        "Ele j√° vai saber do que se trata. S√≥ um momento...",
        
        "Certo! Vou te passar para {agent_name} em {department}. "
        "J√° repassei as informa√ß√µes, ele vai te atender em seguida.",
        
        "Combinado! Te transfiro agora para {department}. "
        "O {agent_name} j√° est√° ciente da sua solicita√ß√£o. Um instante...",
    ]
    
    OFFLINE_MESSAGES = [
        "Infelizmente n√£o h√° atendentes dispon√≠veis no {department} agora. "
        "Vou criar um protocolo de atendimento pra voc√™ e nossa equipe "
        "entrar√° em contato assim que poss√≠vel.",
        
        "No momento o {department} est√° sem atendentes online. "
        "Vou registrar sua solicita√ß√£o como prioridade e voc√™ receber√° "
        "retorno em at√© 24 horas. Pode ser?",
    ]
    
    async def execute_transfer_with_announcement(
        self,
        extension: str,
        department: str,
        agent_name: str,
        context: str
    ) -> TransferResult:
        """Transfer√™ncia com an√∫ncio natural ao cliente."""
        
        # 1. Verificar disponibilidade
        is_available = await self._check_agent_registration(extension)
        
        if not is_available:
            # Caso offline: informar e criar ticket
            message = random.choice(self.OFFLINE_MESSAGES).format(
                department=department
            )
            await self.provider.speak_text(message)
            await asyncio.sleep(3)  # Tempo para falar
            
            # Criar ticket no OmniPlay
            ticket = await self._create_fallback_ticket(context, department)
            return TransferResult(
                status=TransferStatus.OFFLINE,
                ticket_id=ticket.id
            )
        
        # 2. Anunciar ao CLIENTE
        announcement = random.choice(self.TRANSFER_ANNOUNCEMENTS).format(
            agent_name=agent_name,
            department=department
        )
        await self.provider.speak_text(announcement)
        
        # 3. Aguardar conclus√£o do an√∫ncio (estimar dura√ß√£o)
        speech_duration = self._estimate_speech_duration(announcement)
        await asyncio.sleep(speech_duration)
        
        # 4. Colocar em hold com mensagem
        await self.esl.hold("Conectando, aguarde...")
        
        # 5. Anunciar ao ATENDENTE (announced transfer)
        agent_announcement = (
            f"Voc√™ receber√° uma transfer√™ncia. "
            f"Cliente solicitou {context}. "
            f"Conectando em 3 segundos..."
        )
        await self._announce_to_agent(extension, agent_announcement)
        await asyncio.sleep(3)
        
        # 6. Executar transfer√™ncia
        await self.esl.transfer(extension, self.domain)
        
        return TransferResult(
            status=TransferStatus.SUCCESS,
            extension=extension
        )
    
    def _estimate_speech_duration(self, text: str) -> float:
        """Estima dura√ß√£o da fala em segundos."""
        # Aproxima√ß√£o: ~150 palavras por minuto em portugu√™s
        words = len(text.split())
        return (words / 150) * 60 + 0.5  # +500ms de margem
```

**Impacto**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  
- Experi√™ncia de transfer√™ncia profissional
- Cliente sempre sabe o que est√° acontecendo
- Atendente recebe contexto antes de atender

---

#### 4Ô∏è‚É£ Detec√ß√£o de Emo√ß√£o e Adapta√ß√£o de Tom
**Problema**: IA responde igual para usu√°rios frustrados e calmos  
**Solu√ß√£o**: Instru√ß√µes contextuais no prompt

**Localiza√ß√£o**: `voice-ai-service/realtime/config/prompts.py`

```python
EMOTIONAL_ADAPTATION = """
ADAPTA√á√ÉO EMOCIONAL - LEIA ATENTAMENTE:

Detecte o estado emocional do cliente pela fala e adapte sua resposta:

1. CLIENTE FRUSTRADO (tom alterado, reclama√ß√µes, palavr√µes leves):
   - Mostre empatia imediata: "Entendo completamente sua frustra√ß√£o..."
   - Assuma controle: "Vou resolver isso pra voc√™ agora"
   - Seja direto, sem rodeios
   - Priorize a√ß√£o sobre explica√ß√£o
   
   Exemplo:
   ‚ùå "Entendo. Voc√™ poderia me informar seu protocolo?"
   ‚úÖ "Entendo sua frustra√ß√£o. Vou localizar seu atendimento agora. 
       Qual seu nome ou telefone?"

2. CLIENTE APRESSADO (respostas curtas, "r√°pido", "urgente"):
   - Seja extremamente direto
   - Evite sauda√ß√µes longas
   - V√° direto ao ponto
   - Pergunte apenas o essencial
   
   Exemplo:
   ‚ùå "Ol√°! Tudo bem? Como posso ajudar hoje?"
   ‚úÖ "Oi! O que voc√™ precisa?"

3. CLIENTE CONFUSO (muitas perguntas, incerteza):
   - Ofere√ßa explica√ß√µes detalhadas
   - Confirme entendimento: "Deixa eu ver se entendi..."
   - Seja paciente e did√°tico
   - Resuma ao final
   
   Exemplo:
   ‚ùå "Ok, vou transferir."
   ‚úÖ "Deixa eu explicar: vou te passar pro setor financeiro, 
       que cuida de boletos e pagamentos. Eles v√£o conseguir 
       te ajudar com isso. Pode ser?"

4. CLIENTE EDUCADO E CALMO (padr√£o):
   - Mantenha profissionalismo amig√°vel
   - Use tom conversacional natural
   - Seja eficiente mas n√£o apressado

NUNCA pergunte explicitamente sobre emo√ß√µes. 
Apenas ADAPTE-SE naturalmente ao tom da conversa.
"""

# Adicionar ao system prompt
def get_system_prompt(company_name: str, secretary_name: str) -> str:
    return f"""
Voc√™ √© {secretary_name}, secret√°ria virtual da empresa {company_name}.

{CONVERSATIONAL_RULES}
{EMOTIONAL_ADAPTATION}

Suas principais fun√ß√µes: [...]
"""
```

**Impacto**: ‚≠ê‚≠ê‚≠ê‚≠ê  
- Melhora satisfa√ß√£o em ~40% (usu√°rios frustrados)
- Zero c√≥digo adicional
- Funciona via an√°lise sem√¢ntica do OpenAI

---

#### 5Ô∏è‚É£ Mem√≥ria de Contexto Curto
**Problema**: IA n√£o referencia informa√ß√µes mencionadas antes  
**Solu√ß√£o**: Instru√ß√µes de coer√™ncia + uso natural do hist√≥rico

**Localiza√ß√£o**: `voice-ai-service/realtime/config/prompts.py`

```python
CONTEXT_COHERENCE = """
COER√äNCIA E MEM√ìRIA CONTEXTUAL:

1. SEMPRE referencie informa√ß√µes j√° fornecidas:
   ‚úÖ "Como voc√™ mencionou sobre o pedido 12345..."
   ‚úÖ "Voltando √† sua d√∫vida sobre o prazo..."
   ‚úÖ "Sobre o departamento que voc√™ pediu..."
   
   ‚ùå "Qual o n√∫mero do pedido?" (se j√° foi dito)
   ‚ùå "Para qual setor voc√™ quer ir?" (se j√° informou)

2. NUNCA pe√ßa informa√ß√µes repetidas:
   - Se o cliente j√° disse o nome, use-o naturalmente
   - Se j√° mencionou um protocolo, n√£o pe√ßa novamente
   - Mantenha contexto de toda a conversa

3. CONECTE t√≥picos naturalmente:
   User: "Meu pedido 12345 atrasou"
   AI: "Vou verificar o pedido 12345... [consulta]"
   AI: "Sobre o atraso que voc√™ mencionou, vejo aqui que..."
   
4. RESUMA quando necess√°rio:
   "Ent√£o, recapitulando: voc√™ precisa de X, Y e Z. Correto?"

Mantenha a conversa fluida como se fosse uma pessoa 
que REALMENTE est√° prestando aten√ß√£o.
"""

# Adicionar ao system prompt
def get_system_prompt(company_name: str, secretary_name: str) -> str:
    return f"""
Voc√™ √© {secretary_name}, secret√°ria virtual da empresa {company_name}.

{CONVERSATIONAL_RULES}
{EMOTIONAL_ADAPTATION}
{CONTEXT_COHERENCE}

Suas principais fun√ß√µes: [...]
"""
```

**Observa√ß√£o**: OpenAI Realtime j√° mant√©m hist√≥rico automaticamente via `conversation.item.create`. Apenas reforce no prompt.

**Impacto**: ‚≠ê‚≠ê‚≠ê‚≠ê  
- Reduz frustra√ß√£o por repeti√ß√£o
- Conversa mais natural e eficiente
- Zero c√≥digo, apenas prompt

---

### **P2 - Refinamentos (Backlog)**

#### 6Ô∏è‚É£ Antecipa√ß√£o de Necessidades
**Localiza√ß√£o**: `voice-ai-service/realtime/config/prompts.py`

```python
PROACTIVE_ASSISTANCE = """
ASSIST√äNCIA PROATIVA:

Ap√≥s resolver uma quest√£o, sugira UMA pr√≥xima a√ß√£o relacionada:

Padr√µes comuns:
- Consultou pedido ‚Üí "Quer saber o prazo de entrega tamb√©m?"
- Resolveu d√∫vida t√©cnica ‚Üí "Precisa de ajuda com outra funcionalidade?"
- Atualizou cadastro ‚Üí "Gostaria de verificar seus outros dados?"
- Transferiu para vendas ‚Üí N√£o sugira nada (j√° est√° transferindo)

REGRAS:
- Apenas 1 sugest√£o por intera√ß√£o
- Seja sutil, n√£o insista
- Se cliente disser "n√£o", n√£o ofere√ßa mais nada
- Priorize o que o cliente PRECISA, n√£o o que voc√™ quer vender

Exemplo:
‚úÖ "Resolvido! Mais alguma coisa que eu possa ajudar?"
‚úÖ "Pronto! Voc√™ tamb√©m precisa do comprovante por email?"
‚ùå "Posso te ajudar com X? E com Y? E com Z?" (muito agressivo)
"""
```

**Impacto**: ‚≠ê‚≠ê‚≠ê  
- Aumenta resolu√ß√£o na primeira chamada
- Melhora percep√ß√£o de utilidade
- Apenas prompt

---

#### 7Ô∏è‚É£ Breathing Room (Pausas Naturais)
**Problema**: IA responde instantaneamente (n√£o humano)  
**Solu√ß√£o**: Delay inteligente antes de respostas

**Localiza√ß√£o**: `voice-ai-service/realtime/session/pacing.py` (criar arquivo novo)

```python
import time
import random
from typing import Optional

class ConversationPacing:
    """Gerencia timing natural de respostas."""
    
    def __init__(self):
        self.last_user_speech_end: Optional[float] = None
        self.natural_delay_range = (0.2, 0.4)  # 200-400ms
        self.quick_response_threshold = 0.15   # <150ms = muito r√°pido
    
    def mark_user_speech_ended(self):
        """Marca o momento em que usu√°rio parou de falar."""
        self.last_user_speech_end = time.time()
    
    async def apply_natural_delay(self) -> None:
        """Adiciona delay se resposta seria artificial r√°pida."""
        if not self.last_user_speech_end:
            return
        
        # Tempo desde fim da fala
        elapsed = time.time() - self.last_user_speech_end
        
        # Se j√° esperou o suficiente, n√£o adicionar delay
        if elapsed >= self.natural_delay_range[0]:
            return
        
        # Calcular delay necess√°rio
        min_delay, max_delay = self.natural_delay_range
        target_delay = random.uniform(min_delay, max_delay)
        remaining_delay = max(0, target_delay - elapsed)
        
        if remaining_delay > 0:
            await asyncio.sleep(remaining_delay)
    
    def reset(self):
        """Reset para nova conversa."""
        self.last_user_speech_end = None
```

**Integra√ß√£o**:
```python
# No OpenAIRealtimeProvider
class OpenAIRealtimeProvider:
    def __init__(self, config):
        # ... existing init
        self.pacing = ConversationPacing()
    
    async def _on_input_audio_buffer_speech_stopped(self, event: dict):
        """Usu√°rio parou de falar."""
        # Marcar timestamp
        self.pacing.mark_user_speech_ended()
        
        # Continuar processamento normal...
    
    async def _on_response_audio_delta(self, event: dict):
        """OpenAI come√ßou a responder."""
        # Aplicar delay natural se necess√°rio
        await self.pacing.apply_natural_delay()
        
        # Enviar √°udio normalmente...
```

**Impacto**: ‚≠ê‚≠ê‚≠ê  
- Mais humanizado
- Pequeno overhead (<400ms)
- C√≥digo simples

---

## üîß Arquitetura de Implementa√ß√£o

### Estrutura de Arquivos Sugerida

```
voice-ai-service/
‚îú‚îÄ‚îÄ realtime/
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py          # ‚Üê NOVO: Todos os prompts centralizados
‚îÇ   ‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openai_realtime.py  # ‚Üê MODIFICAR: Adicionar fillers
‚îÇ   ‚îú‚îÄ‚îÄ session/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pacing.py           # ‚Üê NOVO: Breathing room logic
‚îÇ   ‚îî‚îÄ‚îÄ transfer/
‚îÇ       ‚îî‚îÄ‚îÄ transfer_manager.py  # ‚Üê MODIFICAR: Suaviza√ß√£o
```

### Ordem de Implementa√ß√£o Recomendada

```mermaid
graph TD
    A[1. Criar prompts.py] --> B[2. Atualizar OpenAIRealtimeProvider]
    B --> C[3. Implementar fillers]
    C --> D[4. Testar confirma√ß√µes variadas]
    D --> E[5. Melhorar TransferManager]
    E --> F[6. Adicionar pacing.py]
    F --> G[7. Testes e refinamento]
```

---

## üìä M√©tricas de Sucesso

Ap√≥s implementa√ß√£o, monitorar:

| M√©trica | Antes | Meta | Como Medir |
|---------|-------|------|------------|
| **Satisfa√ß√£o (CSAT)** | Baseline | +20% | Survey p√≥s-chamada |
| **Tempo de Atendimento** | Baseline | -15% | Dura√ß√£o m√©dia das chamadas |
| **Taxa de Transfer√™ncia** | Baseline | -10% | % de chamadas transferidas |
| **Reclama√ß√µes "rob√≥tico"** | Baseline | -80% | An√°lise de feedback |

---

## üöÄ Checklist de Implementa√ß√£o

### P0 - Quick Wins
- [ ] Criar `realtime/config/prompts.py`
- [ ] Adicionar `CONVERSATIONAL_RULES` ao system prompt
- [ ] Implementar `FILLERS` e `PROCESSING_NARRATION`
- [ ] Adicionar `_handle_function_call_start()` no provider
- [ ] Testar com chamadas reais
- [ ] Ajustar prompts baseado em feedback

### P1 - Alto Impacto  
- [ ] Adicionar `EMOTIONAL_ADAPTATION` ao prompt
- [ ] Adicionar `CONTEXT_COHERENCE` ao prompt
- [ ] Refatorar `TransferManager.execute_transfer()`
- [ ] Implementar `execute_transfer_with_announcement()`
- [ ] Adicionar `_estimate_speech_duration()`
- [ ] Testar transfer√™ncias anunciadas
- [ ] Validar offline fallback

### P2 - Refinamentos
- [ ] Adicionar `PROACTIVE_ASSISTANCE` ao prompt
- [ ] Criar `session/pacing.py`
- [ ] Integrar `ConversationPacing` no provider
- [ ] Testar delays naturais
- [ ] A/B test com/sem breathing room

---

## üí° Dicas para o Cursor/Claude

**Ao implementar no Cursor:**

1. **Comece pelos prompts** - Zero risco, alto impacto
2. **Teste incrementalmente** - N√£o implemente tudo de uma vez
3. **Use logs detalhados** - Adicione logging para debug:
   ```python
   logger.info(f"Sending filler: {filler}")
   logger.info(f"Applied natural delay: {delay}ms")
   ```
4. **Preserve compatibilidade** - N√£o quebre integra√ß√µes existentes
5. **Documente decis√µes** - Comente trechos n√£o √≥bvios

**Comandos √∫teis para testar:**
```bash
# Reiniciar servi√ßo
docker-compose restart voice-ai-realtime

# Ver logs em tempo real
docker-compose logs -f voice-ai-realtime

# Testar WebSocket
wscat -c ws://localhost:8085
```

---

## üìö Refer√™ncias

- [OpenAI Realtime API Docs](https://platform.openai.com/docs/guides/realtime)
- [Conversational AI Best Practices](https://cloud.google.com/dialogflow/cx/docs/concept/best-practices)
- [Voice UX Guidelines](https://developer.amazon.com/en-US/docs/alexa/custom-skills/voice-design-best-practices.html)

---

## üéôÔ∏è Ap√™ndice: Formatos de √Åudio OpenAI Realtime API

### Formatos Suportados

A OpenAI Realtime API GA suporta **tr√™s formatos** de √°udio:

| Formato | Sample Rate | Uso Recomendado |
|---------|-------------|-----------------|
| `pcm16` | 24 kHz | Qualidade m√°xima, uso geral |
| `g711_ulaw` | 24 kHz | Compatibilidade telefonia (Am√©rica do Norte) |
| `g711_alaw` | 24 kHz | Compatibilidade telefonia (Europa/resto do mundo) |

### ‚ö†Ô∏è Importante sobre G.711

**A API suporta G.711, MAS apenas @ 24kHz (n√£o o padr√£o 8kHz de telefonia!)**

Isso significa que:
- ‚ùå **N√£o pode** enviar G.711 @ 8kHz direto do FreeSWITCH
- ‚úÖ **Pode** usar G.711 @ 24kHz se ambos os lados suportarem
- üéØ **Melhor abordagem**: PCM16 @ 24kHz (m√°xima qualidade)

### Arquitetura Atual (Correta)

```
Telefone      FreeSWITCH    voice-ai-realtime    OpenAI
G.711 @ 8k ‚Üí PCM16 @ 8k ‚Üí PCM16 @ 24k (resample) ‚Üí PCM16 @ 24k
```

**Por que n√£o usar G.711 direto?**
1. Telefonia padr√£o = G.711 @ **8kHz**
2. OpenAI exige = G.711 @ **24kHz**
3. Ainda precisaria resampling (opera√ß√£o mais custosa)
4. Ganho de usar G.711 vs PCM16 √© m√≠nimo

**Conclus√£o**: A transcodifica√ß√£o atual (G.711 ‚Üî PCM16 + resampling) √© a abordagem correta e n√£o h√° otimiza√ß√£o significativa dispon√≠vel mudando para G.711 @ 24kHz.

### Refer√™ncias T√©cnicas
- [OpenAI Realtime Session API](https://platform.openai.com/docs/api-reference/realtime-beta-sessions)
- [Issue #8 - G.711 8kHz Support](https://github.com/openai/openai-realtime-api-beta/issues/8)

---

**Autor**: An√°lise t√©cnica para implementa√ß√£o no Voice AI IVR  
**Data**: Janeiro 2026  
**Vers√£o**: 1.1 (atualizado com esclarecimentos sobre G.711)
